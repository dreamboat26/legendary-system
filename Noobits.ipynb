{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbs3OEiD2ZZF",
        "outputId": "9b6ffee5-24ad-4be4-de45-e221131bb9e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub-Population 0 | Best Position: -0.8479097605464667 | Best Value: 0.34163625487814214 | Attention Mechanism: {'global_weight': 0.5, 'local_weight': 0.3, 'quantum_weight': 0.2}\n",
            "Sub-Population 1 | Best Position: -0.8545552916262323 | Best Value: 0.3409478919996605 | Attention Mechanism: {'global_weight': 0.4, 'local_weight': 0.4, 'quantum_weight': 0.2}\n",
            "Sub-Population 2 | Best Position: -0.8295058209656913 | Best Value: 0.3406130676646926 | Attention Mechanism: {'global_weight': 0.6, 'local_weight': 0.2, 'quantum_weight': 0.2}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Objective function to optimize\n",
        "def objective_function(x):\n",
        "    \"\"\"Example objective function to optimize.\"\"\"\n",
        "    return np.sin(5 * x) * (1 - np.tanh(x**2))\n",
        "\n",
        "# Quantum Exploration Phase - Simulate a Quantum State\n",
        "def quantum_exploration(num_states):\n",
        "    \"\"\"Simulate quantum state exploration.\"\"\"\n",
        "    state_amplitudes = np.random.rand(num_states)\n",
        "    state_probabilities = state_amplitudes / np.sum(state_amplitudes)\n",
        "    return state_probabilities\n",
        "\n",
        "# Swarm Intelligence with Multiple Sub-Populations\n",
        "def swarm_intelligence_multi_population(num_particles, num_iterations, quantum_probabilities, sub_populations):\n",
        "    \"\"\"\n",
        "    Perform swarm optimization with multiple sub-populations, each with a different attention mechanism.\n",
        "    \"\"\"\n",
        "    # Define attention mechanisms\n",
        "    attention_mechanisms = [\n",
        "        {\"global_weight\": 0.5, \"local_weight\": 0.3, \"quantum_weight\": 0.2},\n",
        "        {\"global_weight\": 0.4, \"local_weight\": 0.4, \"quantum_weight\": 0.2},\n",
        "        {\"global_weight\": 0.6, \"local_weight\": 0.2, \"quantum_weight\": 0.2},\n",
        "    ]\n",
        "\n",
        "    # Initialize data for sub-populations\n",
        "    results = []\n",
        "    for sub_pop in range(sub_populations):\n",
        "        particles = np.random.uniform(-5, 5, num_particles)\n",
        "        velocities = np.zeros(num_particles)\n",
        "        best_positions = np.copy(particles)\n",
        "        global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "        # Get the attention mechanism for this sub-population\n",
        "        mechanism = attention_mechanisms[sub_pop % len(attention_mechanisms)]\n",
        "\n",
        "        for iteration in range(num_iterations):\n",
        "            for i in range(num_particles):\n",
        "                quantum_feedback = np.random.choice(range(len(quantum_probabilities)), p=quantum_probabilities)\n",
        "                direction = (quantum_feedback - num_particles // 2) / (num_particles // 2)\n",
        "\n",
        "                # Update velocity and position using the unique attention mechanism\n",
        "                velocities[i] = (mechanism[\"local_weight\"] * velocities[i] +\n",
        "                                 mechanism[\"local_weight\"] * np.random.rand() * (best_positions[i] - particles[i]) +\n",
        "                                 mechanism[\"global_weight\"] * np.random.rand() * (global_best_position - particles[i]) +\n",
        "                                 mechanism[\"quantum_weight\"] * direction)\n",
        "                particles[i] += velocities[i]\n",
        "\n",
        "                # Update local best position\n",
        "                if objective_function(particles[i]) > objective_function(best_positions[i]):\n",
        "                    best_positions[i] = particles[i]\n",
        "\n",
        "            # Update global best position\n",
        "            global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "            # Feedback Loop\n",
        "            quantum_probabilities = quantum_exploration(len(quantum_probabilities))\n",
        "\n",
        "        # Store results for this sub-population\n",
        "        results.append({\n",
        "            \"sub_population\": sub_pop,\n",
        "            \"best_position\": global_best_position,\n",
        "            \"best_value\": objective_function(global_best_position),\n",
        "            \"attention_mechanism\": mechanism\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Set parameters\n",
        "num_states = 10\n",
        "num_particles = 20\n",
        "num_iterations = 30\n",
        "sub_populations = 3  # Number of sub-populations\n",
        "\n",
        "# Initialize quantum state probabilities\n",
        "quantum_probabilities = quantum_exploration(num_states)\n",
        "\n",
        "# Run the Quantum-Swarm Hybrid Algorithm with multiple sub-populations\n",
        "results = swarm_intelligence_multi_population(num_particles, num_iterations, quantum_probabilities, sub_populations)\n",
        "\n",
        "# Display the results\n",
        "for result in results:\n",
        "    print(f\"Sub-Population {result['sub_population']} | Best Position: {result['best_position']} | \"\n",
        "          f\"Best Value: {result['best_value']} | Attention Mechanism: {result['attention_mechanism']}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Objective function to optimize\n",
        "def objective_function(x):\n",
        "    \"\"\"Example objective function to optimize.\"\"\"\n",
        "    return np.sin(5 * x) * (1 - np.tanh(x**2))\n",
        "\n",
        "# Quantum Exploration Phase - Simulate a Quantum State\n",
        "def quantum_exploration(num_states):\n",
        "    \"\"\"Simulate quantum state exploration.\"\"\"\n",
        "    state_amplitudes = np.random.rand(num_states)\n",
        "    state_probabilities = state_amplitudes / np.sum(state_amplitudes)\n",
        "    return state_probabilities\n",
        "\n",
        "# Swarm Intelligence with Adaptive Mechanisms\n",
        "def swarm_intelligence_adaptive(num_particles, num_iterations, quantum_probabilities, sub_populations):\n",
        "    \"\"\"\n",
        "    Perform swarm optimization with multiple sub-populations, each with adaptive attention mechanisms.\n",
        "    \"\"\"\n",
        "    # Initialize data for sub-populations\n",
        "    results = []\n",
        "    for sub_pop in range(sub_populations):\n",
        "        particles = np.random.uniform(-5, 5, num_particles)\n",
        "        velocities = np.zeros(num_particles)\n",
        "        best_positions = np.copy(particles)\n",
        "        global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "        # Initialize adaptive attention mechanism\n",
        "        global_weight = 0.5\n",
        "        local_weight = 0.3\n",
        "        quantum_weight = 0.2\n",
        "        learning_rate = 0.05  # Learning rate for adaptive updates\n",
        "\n",
        "        for iteration in range(num_iterations):\n",
        "            for i in range(num_particles):\n",
        "                quantum_feedback = np.random.choice(range(len(quantum_probabilities)), p=quantum_probabilities)\n",
        "                direction = (quantum_feedback - num_particles // 2) / (num_particles // 2)\n",
        "\n",
        "                # Update velocity and position using the adaptive attention mechanism\n",
        "                velocities[i] = (local_weight * velocities[i] +\n",
        "                                 local_weight * np.random.rand() * (best_positions[i] - particles[i]) +\n",
        "                                 global_weight * np.random.rand() * (global_best_position - particles[i]) +\n",
        "                                 quantum_weight * direction)\n",
        "                particles[i] += velocities[i]\n",
        "\n",
        "                # Update local best position\n",
        "                if objective_function(particles[i]) > objective_function(best_positions[i]):\n",
        "                    best_positions[i] = particles[i]\n",
        "\n",
        "            # Update global best position\n",
        "            global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "            # Adaptive mechanism: Adjust weights based on progress\n",
        "            if iteration > 0 and iteration % 5 == 0:\n",
        "                # Decrease quantum influence if progress stagnates\n",
        "                if results and results[-1]['best_value'] == objective_function(global_best_position):\n",
        "                    quantum_weight = max(0.1, quantum_weight - learning_rate)\n",
        "                    global_weight += learning_rate / 2\n",
        "                    local_weight += learning_rate / 2\n",
        "                else:\n",
        "                    # Increase quantum influence if still exploring\n",
        "                    quantum_weight = min(0.3, quantum_weight + learning_rate)\n",
        "                    global_weight = max(0.4, global_weight - learning_rate / 2)\n",
        "                    local_weight = max(0.2, local_weight - learning_rate / 2)\n",
        "\n",
        "            # Feedback Loop\n",
        "            quantum_probabilities = quantum_exploration(len(quantum_probabilities))\n",
        "\n",
        "        # Store results for this sub-population\n",
        "        results.append({\n",
        "            \"sub_population\": sub_pop,\n",
        "            \"best_position\": global_best_position,\n",
        "            \"best_value\": objective_function(global_best_position),\n",
        "            \"attention_mechanism\": {'global_weight': global_weight, 'local_weight': local_weight, 'quantum_weight': quantum_weight}\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Set parameters\n",
        "num_states = 10\n",
        "num_particles = 20\n",
        "num_iterations = 30\n",
        "sub_populations = 3  # Number of sub-populations\n",
        "\n",
        "# Initialize quantum state probabilities\n",
        "quantum_probabilities = quantum_exploration(num_states)\n",
        "\n",
        "# Run the Quantum-Swarm Hybrid Algorithm with adaptive mechanisms\n",
        "results = swarm_intelligence_adaptive(num_particles, num_iterations, quantum_probabilities, sub_populations)\n",
        "\n",
        "# Display the results\n",
        "for result in results:\n",
        "    print(f\"Sub-Population {result['sub_population']} | Best Position: {result['best_position']} | \"\n",
        "          f\"Best Value: {result['best_value']} | Attention Mechanism: {result['attention_mechanism']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm5s4OJG3vQB",
        "outputId": "f6565c42-3c6d-42a9-ba2b-de3ba9c1c94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub-Population 0 | Best Position: -0.8335157177994693 | Best Value: 0.34121462397216745 | Attention Mechanism: {'global_weight': 0.4, 'local_weight': 0.2, 'quantum_weight': 0.3}\n",
            "Sub-Population 1 | Best Position: -0.8141062125033283 | Best Value: 0.336250894157757 | Attention Mechanism: {'global_weight': 0.4, 'local_weight': 0.2, 'quantum_weight': 0.3}\n",
            "Sub-Population 2 | Best Position: -0.9722624509850739 | Best Value: 0.25945085885153213 | Attention Mechanism: {'global_weight': 0.4, 'local_weight': 0.2, 'quantum_weight': 0.3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Objective function to optimize\n",
        "def objective_function(x):\n",
        "    \"\"\"Example objective function to optimize.\"\"\"\n",
        "    return np.sin(5 * x) * (1 - np.tanh(x**2))\n",
        "\n",
        "# Quantum Exploration Phase - Simulate a Quantum State\n",
        "def quantum_exploration(num_states):\n",
        "    \"\"\"Simulate quantum state exploration.\"\"\"\n",
        "    state_amplitudes = np.random.rand(num_states)\n",
        "    state_probabilities = state_amplitudes / np.sum(state_amplitudes)\n",
        "    return state_probabilities\n",
        "\n",
        "# Swarm Intelligence with Enhanced Adaptive Mechanisms\n",
        "def swarm_intelligence_enhanced(num_particles, num_iterations, quantum_probabilities, sub_populations):\n",
        "    \"\"\"\n",
        "    Perform swarm optimization with multiple sub-populations, each with an enhanced adaptive attention mechanism.\n",
        "    \"\"\"\n",
        "    # Initialize data for sub-populations\n",
        "    results = []\n",
        "    for sub_pop in range(sub_populations):\n",
        "        particles = np.random.uniform(-5, 5, num_particles)\n",
        "        velocities = np.zeros(num_particles)\n",
        "        best_positions = np.copy(particles)\n",
        "        global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "        # Initialize adaptive attention mechanism with more diversity\n",
        "        global_weight = np.random.uniform(0.2, 0.6)\n",
        "        local_weight = np.random.uniform(0.2, 0.6)\n",
        "        quantum_weight = np.random.uniform(0.1, 0.4)\n",
        "        learning_rate = 0.05  # Learning rate for adaptive updates\n",
        "        decay_factor = 0.98  # Gradual reduction of quantum influence over time\n",
        "\n",
        "        for iteration in range(num_iterations):\n",
        "            for i in range(num_particles):\n",
        "                quantum_feedback = np.random.choice(range(len(quantum_probabilities)), p=quantum_probabilities)\n",
        "                direction = (quantum_feedback - num_particles // 2) / (num_particles // 2)\n",
        "\n",
        "                # Update velocity and position using the enhanced adaptive attention mechanism\n",
        "                velocities[i] = (local_weight * velocities[i] +\n",
        "                                 local_weight * np.random.rand() * (best_positions[i] - particles[i]) +\n",
        "                                 global_weight * np.random.rand() * (global_best_position - particles[i]) +\n",
        "                                 quantum_weight * direction)\n",
        "                particles[i] += velocities[i]\n",
        "\n",
        "                # Update local best position\n",
        "                if objective_function(particles[i]) > objective_function(best_positions[i]):\n",
        "                    best_positions[i] = particles[i]\n",
        "\n",
        "            # Update global best position\n",
        "            global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "            # Enhanced adaptive mechanism: Adjust weights with momentum and decay\n",
        "            if iteration > 0 and iteration % 5 == 0:\n",
        "                # Decrease quantum influence with decay factor over time\n",
        "                quantum_weight *= decay_factor\n",
        "\n",
        "                # Adjust weights more dynamically\n",
        "                if results and results[-1]['best_value'] == objective_function(global_best_position):\n",
        "                    # Larger adjustment if no progress\n",
        "                    quantum_weight = max(0.1, quantum_weight - learning_rate * 2)\n",
        "                    global_weight = min(0.6, global_weight + learning_rate)\n",
        "                    local_weight = min(0.6, local_weight + learning_rate)\n",
        "                else:\n",
        "                    # Smaller adjustment during progress\n",
        "                    quantum_weight = min(0.4, quantum_weight + learning_rate * decay_factor)\n",
        "                    global_weight = max(0.2, global_weight - learning_rate / 2)\n",
        "                    local_weight = max(0.2, local_weight - learning_rate / 2)\n",
        "\n",
        "            # Feedback Loop\n",
        "            quantum_probabilities = quantum_exploration(len(quantum_probabilities))\n",
        "\n",
        "        # Store results for this sub-population\n",
        "        results.append({\n",
        "            \"sub_population\": sub_pop,\n",
        "            \"best_position\": global_best_position,\n",
        "            \"best_value\": objective_function(global_best_position),\n",
        "            \"attention_mechanism\": {'global_weight': global_weight, 'local_weight': local_weight, 'quantum_weight': quantum_weight}\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Set parameters\n",
        "num_states = 10\n",
        "num_particles = 20\n",
        "num_iterations = 30\n",
        "sub_populations = 3  # Number of sub-populations\n",
        "\n",
        "# Initialize quantum state probabilities\n",
        "quantum_probabilities = quantum_exploration(num_states)\n",
        "\n",
        "# Run the Quantum-Swarm Hybrid Algorithm with enhanced adaptive mechanisms\n",
        "results = swarm_intelligence_enhanced(num_particles, num_iterations, quantum_probabilities, sub_populations)\n",
        "\n",
        "# Display the results\n",
        "for result in results:\n",
        "    print(f\"Sub-Population {result['sub_population']} | Best Position: {result['best_position']} | \"\n",
        "          f\"Best Value: {result['best_value']} | Attention Mechanism: {result['attention_mechanism']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI1z0J9r4PYA",
        "outputId": "90e6187f-3044-4e79-f700-f2d9944ae6fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub-Population 0 | Best Position: -0.8501483189607685 | Best Value: 0.3414650264633249 | Attention Mechanism: {'global_weight': 0.3424518356608105, 'local_weight': 0.22849321619965704, 'quantum_weight': 0.4}\n",
            "Sub-Population 1 | Best Position: -0.8364920620927245 | Best Value: 0.34152248562869664 | Attention Mechanism: {'global_weight': 0.29378589761008334, 'local_weight': 0.37854772026209793, 'quantum_weight': 0.3827414643783761}\n",
            "Sub-Population 2 | Best Position: -0.859963879366042 | Best Value: 0.33999357342430925 | Attention Mechanism: {'global_weight': 0.2, 'local_weight': 0.3257362863683259, 'quantum_weight': 0.4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Objective function to optimize\n",
        "def objective_function(x):\n",
        "    \"\"\"Example objective function to optimize.\"\"\"\n",
        "    return np.sin(5 * x) * (1 - np.tanh(x**2))\n",
        "\n",
        "# Quantum Exploration Phase - Simulate a Quantum State\n",
        "def quantum_exploration(num_states):\n",
        "    \"\"\"Simulate quantum state exploration.\"\"\"\n",
        "    state_amplitudes = np.random.rand(num_states)\n",
        "    state_probabilities = state_amplitudes / np.sum(state_amplitudes)\n",
        "    return state_probabilities\n",
        "\n",
        "# Enhanced Swarm Intelligence with Dynamic Quantum Influence and Multi-Phase Approach\n",
        "def swarm_intelligence_multi_phase(num_particles, num_iterations, quantum_probabilities, sub_populations):\n",
        "    \"\"\"\n",
        "    Perform swarm optimization with multiple sub-populations, each with a multi-phase adaptive attention mechanism.\n",
        "    \"\"\"\n",
        "    # Initialize data for sub-populations\n",
        "    results = []\n",
        "    for sub_pop in range(sub_populations):\n",
        "        particles = np.random.uniform(-5, 5, num_particles)\n",
        "        velocities = np.zeros(num_particles)\n",
        "        best_positions = np.copy(particles)\n",
        "        global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "        # Initialize adaptive attention mechanism with more diversity\n",
        "        global_weight = np.random.uniform(0.2, 0.6)\n",
        "        local_weight = np.random.uniform(0.2, 0.6)\n",
        "        quantum_weight = np.random.uniform(0.1, 0.4)\n",
        "        learning_rate = 0.05  # Learning rate for adaptive updates\n",
        "        decay_factor = 0.98  # Gradual reduction of quantum influence over time\n",
        "\n",
        "        # Phase control parameters\n",
        "        exploration_phase = True\n",
        "        phase_switch_point = num_iterations // 2  # Switch from exploration to exploitation halfway\n",
        "\n",
        "        for iteration in range(num_iterations):\n",
        "            for i in range(num_particles):\n",
        "                quantum_feedback = np.random.choice(range(len(quantum_probabilities)), p=quantum_probabilities)\n",
        "                direction = (quantum_feedback - num_particles // 2) / (num_particles // 2)\n",
        "\n",
        "                # Update velocity and position using the dynamic quantum influence mechanism\n",
        "                velocities[i] = (local_weight * velocities[i] +\n",
        "                                 local_weight * np.random.rand() * (best_positions[i] - particles[i]) +\n",
        "                                 global_weight * np.random.rand() * (global_best_position - particles[i]) +\n",
        "                                 quantum_weight * direction)\n",
        "                particles[i] += velocities[i]\n",
        "\n",
        "                # Update local best position\n",
        "                if objective_function(particles[i]) > objective_function(best_positions[i]):\n",
        "                    best_positions[i] = particles[i]\n",
        "\n",
        "            # Update global best position\n",
        "            global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "            # Adaptive mechanism with dynamic quantum influence\n",
        "            if exploration_phase and iteration >= phase_switch_point:\n",
        "                # Switch to exploitation phase\n",
        "                exploration_phase = False\n",
        "                quantum_weight = 0.1  # Reduce quantum influence\n",
        "                global_weight = 0.6  # Increase global weight\n",
        "                local_weight = 0.3   # Moderate local weight\n",
        "\n",
        "            if not exploration_phase:\n",
        "                # Further decay quantum influence in the exploitation phase\n",
        "                quantum_weight *= decay_factor\n",
        "\n",
        "            # Feedback Loop\n",
        "            quantum_probabilities = quantum_exploration(len(quantum_probabilities))\n",
        "\n",
        "        # Store results for this sub-population\n",
        "        results.append({\n",
        "            \"sub_population\": sub_pop,\n",
        "            \"best_position\": global_best_position,\n",
        "            \"best_value\": objective_function(global_best_position),\n",
        "            \"attention_mechanism\": {'global_weight': global_weight, 'local_weight': local_weight, 'quantum_weight': quantum_weight}\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Set parameters\n",
        "num_states = 10\n",
        "num_particles = 20\n",
        "num_iterations = 30\n",
        "sub_populations = 3  # Number of sub-populations\n",
        "\n",
        "# Initialize quantum state probabilities\n",
        "quantum_probabilities = quantum_exploration(num_states)\n",
        "\n",
        "# Run the Quantum-Swarm Hybrid Algorithm with dynamic quantum influence and multi-phase approach\n",
        "results = swarm_intelligence_multi_phase(num_particles, num_iterations, quantum_probabilities, sub_populations)\n",
        "\n",
        "# Display the results\n",
        "for result in results:\n",
        "    print(f\"Sub-Population {result['sub_population']} | Best Position: {result['best_position']} | \"\n",
        "          f\"Best Value: {result['best_value']} | Attention Mechanism: {result['attention_mechanism']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbrKlU994puA",
        "outputId": "121fcfa8-ec34-4bf8-f600-60267c067d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub-Population 0 | Best Position: 0.1240592933643856 | Best Value: 0.5723308734201353 | Attention Mechanism: {'global_weight': 0.6, 'local_weight': 0.3, 'quantum_weight': 0.07385691026454037}\n",
            "Sub-Population 1 | Best Position: -0.8529682687690564 | Best Value: 0.3411613978042542 | Attention Mechanism: {'global_weight': 0.6, 'local_weight': 0.3, 'quantum_weight': 0.07385691026454037}\n",
            "Sub-Population 2 | Best Position: 0.19804101396409277 | Best Value: 0.803361730487472 | Attention Mechanism: {'global_weight': 0.6, 'local_weight': 0.3, 'quantum_weight': 0.07385691026454037}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Objective function to optimize\n",
        "def objective_function(x):\n",
        "    \"\"\"Example objective function to optimize.\"\"\"\n",
        "    return np.sin(5 * x) * (1 - np.tanh(x**2))\n",
        "\n",
        "# Quantum Exploration Phase - Simulate a Quantum State\n",
        "def quantum_exploration(num_states):\n",
        "    \"\"\"Simulate quantum state exploration.\"\"\"\n",
        "    state_amplitudes = np.random.rand(num_states)\n",
        "    state_probabilities = state_amplitudes / np.sum(state_amplitudes)\n",
        "    return state_probabilities\n",
        "\n",
        "# Enhanced Swarm Intelligence with Performance-Based Phase Transition\n",
        "def swarm_intelligence_performance_based(num_particles, num_iterations, quantum_probabilities, sub_populations):\n",
        "    \"\"\"\n",
        "    Perform swarm optimization with multiple sub-populations, using performance-based phase transition.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for sub_pop in range(sub_populations):\n",
        "        particles = np.random.uniform(-5, 5, num_particles)\n",
        "        velocities = np.zeros(num_particles)\n",
        "        best_positions = np.copy(particles)\n",
        "        global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "        # Initialize adaptive attention mechanism with more diversity\n",
        "        global_weight = np.random.uniform(0.2, 0.6)\n",
        "        local_weight = np.random.uniform(0.2, 0.6)\n",
        "        quantum_weight = np.random.uniform(0.1, 0.4)\n",
        "        learning_rate = 0.05  # Learning rate for adaptive updates\n",
        "        decay_factor = 0.98  # Gradual reduction of quantum influence over time\n",
        "\n",
        "        # Phase control parameters\n",
        "        exploration_phase = True\n",
        "        phase_switch_threshold = 5  # Number of iterations without improvement to switch phase\n",
        "\n",
        "        no_improvement_counter = 0\n",
        "\n",
        "        for iteration in range(num_iterations):\n",
        "            for i in range(num_particles):\n",
        "                quantum_feedback = np.random.choice(range(len(quantum_probabilities)), p=quantum_probabilities)\n",
        "                direction = (quantum_feedback - num_particles // 2) / (num_particles // 2)\n",
        "\n",
        "                # Update velocity and position using the performance-based mechanism\n",
        "                velocities[i] = (local_weight * velocities[i] +\n",
        "                                 local_weight * np.random.rand() * (best_positions[i] - particles[i]) +\n",
        "                                 global_weight * np.random.rand() * (global_best_position - particles[i]) +\n",
        "                                 quantum_weight * direction)\n",
        "                particles[i] += velocities[i]\n",
        "\n",
        "                # Update local best position\n",
        "                if objective_function(particles[i]) > objective_function(best_positions[i]):\n",
        "                    best_positions[i] = particles[i]\n",
        "\n",
        "            # Update global best position\n",
        "            current_best_value = objective_function(global_best_position)\n",
        "            global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "            # Check for performance-based phase transition\n",
        "            if objective_function(global_best_position) <= current_best_value:\n",
        "                no_improvement_counter += 1\n",
        "            else:\n",
        "                no_improvement_counter = 0  # Reset counter on improvement\n",
        "\n",
        "            if exploration_phase and no_improvement_counter >= phase_switch_threshold:\n",
        "                # Switch to exploitation phase\n",
        "                exploration_phase = False\n",
        "                quantum_weight = 0.1  # Reduce quantum influence\n",
        "                global_weight = 0.6  # Increase global weight\n",
        "                local_weight = 0.3   # Moderate local weight\n",
        "\n",
        "            if not exploration_phase:\n",
        "                # Further decay quantum influence in the exploitation phase\n",
        "                quantum_weight *= decay_factor\n",
        "\n",
        "            # Feedback Loop\n",
        "            quantum_probabilities = quantum_exploration(len(quantum_probabilities))\n",
        "\n",
        "        # Store results for this sub-population\n",
        "        results.append({\n",
        "            \"sub_population\": sub_pop,\n",
        "            \"best_position\": global_best_position,\n",
        "            \"best_value\": objective_function(global_best_position),\n",
        "            \"attention_mechanism\": {'global_weight': global_weight, 'local_weight': local_weight, 'quantum_weight': quantum_weight}\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Set parameters\n",
        "num_states = 10\n",
        "num_particles = 20\n",
        "num_iterations = 30\n",
        "sub_populations = 3  # Number of sub-populations\n",
        "\n",
        "# Initialize quantum state probabilities\n",
        "quantum_probabilities = quantum_exploration(num_states)\n",
        "\n",
        "# Run the Quantum-Swarm Hybrid Algorithm with performance-based phase transition\n",
        "results = swarm_intelligence_performance_based(num_particles, num_iterations, quantum_probabilities, sub_populations)\n",
        "\n",
        "# Display the results\n",
        "for result in results:\n",
        "    print(f\"Sub-Population {result['sub_population']} | Best Position: {result['best_position']} | \"\n",
        "          f\"Best Value: {result['best_value']} | Attention Mechanism: {result['attention_mechanism']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghEt7w1-5HS8",
        "outputId": "b686cb90-2df4-4812-b456-defa06e0fc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub-Population 0 | Best Position: -0.8907326038203636 | Best Value: 0.32836138652416075 | Attention Mechanism: {'global_weight': 0.3920029733269331, 'local_weight': 0.39780392269410914, 'quantum_weight': 0.3714220522962567}\n",
            "Sub-Population 1 | Best Position: -0.9246247659233697 | Best Value: 0.30514347179004925 | Attention Mechanism: {'global_weight': 0.3663422969171719, 'local_weight': 0.5464127379164267, 'quantum_weight': 0.39288190321634175}\n",
            "Sub-Population 2 | Best Position: -0.7920371546997307 | Best Value: 0.3240518278959841 | Attention Mechanism: {'global_weight': 0.6, 'local_weight': 0.3, 'quantum_weight': 0.09604}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Objective function to optimize\n",
        "def objective_function(x):\n",
        "    \"\"\"Example objective function to optimize.\"\"\"\n",
        "    return np.sin(5 * x) * (1 - np.tanh(x**2))\n",
        "\n",
        "# Quantum Exploration Phase - Simulate a Quantum State\n",
        "def quantum_exploration(num_states):\n",
        "    \"\"\"Simulate quantum state exploration.\"\"\"\n",
        "    state_amplitudes = np.random.rand(num_states)\n",
        "    state_probabilities = state_amplitudes / np.sum(state_amplitudes)\n",
        "    return state_probabilities\n",
        "\n",
        "# Swarm Intelligence with Minimum Quantum Influence and Multiple Phase Transitions\n",
        "def swarm_intelligence_multi_transition(num_particles, num_iterations, quantum_probabilities, sub_populations):\n",
        "    \"\"\"\n",
        "    Perform swarm optimization with multiple sub-populations, using a minimum quantum influence and multiple phase transitions.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for sub_pop in range(sub_populations):\n",
        "        particles = np.random.uniform(-5, 5, num_particles)\n",
        "        velocities = np.zeros(num_particles)\n",
        "        best_positions = np.copy(particles)\n",
        "        global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "        # Initialize adaptive attention mechanism with more diversity\n",
        "        global_weight = np.random.uniform(0.2, 0.6)\n",
        "        local_weight = np.random.uniform(0.2, 0.6)\n",
        "        quantum_weight = np.random.uniform(0.1, 0.4)\n",
        "        learning_rate = 0.05  # Learning rate for adaptive updates\n",
        "        decay_factor = 0.98  # Gradual reduction of quantum influence over time\n",
        "        min_quantum_weight = 0.1  # Minimum threshold for quantum influence\n",
        "\n",
        "        # Phase control parameters\n",
        "        exploration_phase = True\n",
        "        phase_switch_threshold = 5  # Number of iterations without improvement to switch phase\n",
        "        no_improvement_counter = 0\n",
        "\n",
        "        for iteration in range(num_iterations):\n",
        "            for i in range(num_particles):\n",
        "                quantum_feedback = np.random.choice(range(len(quantum_probabilities)), p=quantum_probabilities)\n",
        "                direction = (quantum_feedback - num_particles // 2) / (num_particles // 2)\n",
        "\n",
        "                # Update velocity and position using the performance-based mechanism\n",
        "                velocities[i] = (local_weight * velocities[i] +\n",
        "                                 local_weight * np.random.rand() * (best_positions[i] - particles[i]) +\n",
        "                                 global_weight * np.random.rand() * (global_best_position - particles[i]) +\n",
        "                                 quantum_weight * direction)\n",
        "                particles[i] += velocities[i]\n",
        "\n",
        "                # Update local best position\n",
        "                if objective_function(particles[i]) > objective_function(best_positions[i]):\n",
        "                    best_positions[i] = particles[i]\n",
        "\n",
        "            # Update global best position\n",
        "            current_best_value = objective_function(global_best_position)\n",
        "            global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "            # Check for performance-based phase transition\n",
        "            if objective_function(global_best_position) <= current_best_value:\n",
        "                no_improvement_counter += 1\n",
        "            else:\n",
        "                no_improvement_counter = 0  # Reset counter on improvement\n",
        "\n",
        "            if exploration_phase and no_improvement_counter >= phase_switch_threshold:\n",
        "                # Switch to exploitation phase\n",
        "                exploration_phase = False\n",
        "                quantum_weight = max(min_quantum_weight, quantum_weight * decay_factor)\n",
        "                global_weight = 0.6  # Increase global weight\n",
        "                local_weight = 0.3   # Moderate local weight\n",
        "\n",
        "            elif not exploration_phase and no_improvement_counter >= phase_switch_threshold:\n",
        "                # Switch back to exploration phase after prolonged lack of improvement\n",
        "                exploration_phase = True\n",
        "                quantum_weight = min(0.4, quantum_weight + learning_rate)\n",
        "                global_weight = 0.3  # Reduce global weight\n",
        "                local_weight = 0.4   # Increase local weight\n",
        "\n",
        "            # Feedback Loop\n",
        "            quantum_probabilities = quantum_exploration(len(quantum_probabilities))\n",
        "\n",
        "        # Store results for this sub-population\n",
        "        results.append({\n",
        "            \"sub_population\": sub_pop,\n",
        "            \"best_position\": global_best_position,\n",
        "            \"best_value\": objective_function(global_best_position),\n",
        "            \"attention_mechanism\": {'global_weight': global_weight, 'local_weight': local_weight, 'quantum_weight': quantum_weight}\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Set parameters\n",
        "num_states = 10\n",
        "num_particles = 20\n",
        "num_iterations = 30\n",
        "sub_populations = 3  # Number of sub-populations\n",
        "\n",
        "# Initialize quantum state probabilities\n",
        "quantum_probabilities = quantum_exploration(num_states)\n",
        "\n",
        "# Run the Quantum-Swarm Hybrid Algorithm with minimum quantum influence and multiple phase transitions\n",
        "results = swarm_intelligence_multi_transition(num_particles, num_iterations, quantum_probabilities, sub_populations)\n",
        "\n",
        "# Display the results\n",
        "for result in results:\n",
        "    print(f\"Sub-Population {result['sub_population']} | Best Position: {result['best_position']} | \"\n",
        "          f\"Best Value: {result['best_value']} | Attention Mechanism: {result['attention_mechanism']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T0KDosW5fA1",
        "outputId": "d7c1875f-bb86-4013-8f4e-35ed3e41dee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub-Population 0 | Best Position: -0.8299999599153053 | Best Value: 0.34069888377524044 | Attention Mechanism: {'global_weight': 0.5042540254035976, 'local_weight': 0.47697787333005875, 'quantum_weight': 0.37405084601069405}\n",
            "Sub-Population 1 | Best Position: 0.08863512465443393 | Best Value: 0.42544171780534873 | Attention Mechanism: {'global_weight': 0.40876909073361467, 'local_weight': 0.3011868810202175, 'quantum_weight': 0.11870756980179833}\n",
            "Sub-Population 2 | Best Position: -0.8238084638523054 | Best Value: 0.3393832849376151 | Attention Mechanism: {'global_weight': 0.3, 'local_weight': 0.4, 'quantum_weight': 0.1893948210524234}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Objective function to optimize\n",
        "def objective_function(x):\n",
        "    \"\"\"Example objective function to optimize.\"\"\"\n",
        "    return np.sin(5 * x) * (1 - np.tanh(x**2))\n",
        "\n",
        "# Quantum Exploration Phase - Simulate a Quantum State\n",
        "def quantum_exploration(num_states):\n",
        "    \"\"\"Simulate quantum state exploration.\"\"\"\n",
        "    state_amplitudes = np.random.rand(num_states)\n",
        "    state_probabilities = state_amplitudes / np.sum(state_amplitudes)\n",
        "    return state_probabilities\n",
        "\n",
        "# Swarm Intelligence with Targeted Quantum Influence and Different Learning Rates\n",
        "def swarm_intelligence_targeted(num_particles, num_iterations, quantum_probabilities, sub_populations):\n",
        "    \"\"\"\n",
        "    Perform swarm optimization with multiple sub-populations, using targeted quantum influence and different learning rates.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for sub_pop in range(sub_populations):\n",
        "        particles = np.random.uniform(-5, 5, num_particles)\n",
        "        velocities = np.zeros(num_particles)\n",
        "        best_positions = np.copy(particles)\n",
        "        global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "        # Initialize adaptive attention mechanism with more diversity\n",
        "        global_weight = np.random.uniform(0.2, 0.6)\n",
        "        local_weight = np.random.uniform(0.2, 0.6)\n",
        "        quantum_weight = np.random.uniform(0.1, 0.4)\n",
        "        learning_rate_global = 0.03  # Learning rate for global weight updates\n",
        "        learning_rate_local = 0.03   # Learning rate for local weight updates\n",
        "        learning_rate_quantum = 0.05  # Learning rate for quantum weight updates\n",
        "        decay_factor = 0.98  # Gradual reduction of quantum influence over time\n",
        "        min_quantum_weight = 0.1  # Minimum threshold for quantum influence\n",
        "\n",
        "        # Phase control parameters\n",
        "        exploration_phase = True\n",
        "        phase_switch_threshold = 5  # Number of iterations without improvement to switch phase\n",
        "        no_improvement_counter = 0\n",
        "\n",
        "        for iteration in range(num_iterations):\n",
        "            for i in range(num_particles):\n",
        "                quantum_feedback = np.random.choice(range(len(quantum_probabilities)), p=quantum_probabilities)\n",
        "                direction = (quantum_feedback - num_particles // 2) / (num_particles // 2)\n",
        "\n",
        "                # Update velocity and position using the performance-based mechanism\n",
        "                velocities[i] = (local_weight * velocities[i] +\n",
        "                                 local_weight * np.random.rand() * (best_positions[i] - particles[i]) +\n",
        "                                 global_weight * np.random.rand() * (global_best_position - particles[i]) +\n",
        "                                 quantum_weight * direction)\n",
        "                particles[i] += velocities[i]\n",
        "\n",
        "                # Update local best position\n",
        "                if objective_function(particles[i]) > objective_function(best_positions[i]):\n",
        "                    best_positions[i] = particles[i]\n",
        "\n",
        "            # Update global best position\n",
        "            current_best_value = objective_function(global_best_position)\n",
        "            global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "            # Check for performance-based phase transition\n",
        "            if objective_function(global_best_position) <= current_best_value:\n",
        "                no_improvement_counter += 1\n",
        "            else:\n",
        "                no_improvement_counter = 0  # Reset counter on improvement\n",
        "\n",
        "            if exploration_phase and no_improvement_counter >= phase_switch_threshold:\n",
        "                # Switch to exploitation phase\n",
        "                exploration_phase = False\n",
        "                quantum_weight = max(min_quantum_weight, quantum_weight * decay_factor)\n",
        "                global_weight = min(0.6, global_weight + learning_rate_global)\n",
        "                local_weight = min(0.4, local_weight + learning_rate_local)\n",
        "\n",
        "            elif not exploration_phase and no_improvement_counter >= phase_switch_threshold:\n",
        "                # Switch back to exploration phase after prolonged lack of improvement\n",
        "                exploration_phase = True\n",
        "                quantum_weight = min(0.4, quantum_weight + learning_rate_quantum)\n",
        "                global_weight = max(0.3, global_weight - learning_rate_global)\n",
        "                local_weight = max(0.4, local_weight + learning_rate_local)\n",
        "\n",
        "            # Add a mutation-based exploration step to escape local optima\n",
        "            if no_improvement_counter > phase_switch_threshold * 2:\n",
        "                # Randomly perturb the best position to introduce diversity\n",
        "                global_best_position += np.random.uniform(-0.1, 0.1)\n",
        "\n",
        "            # Feedback Loop\n",
        "            quantum_probabilities = quantum_exploration(len(quantum_probabilities))\n",
        "\n",
        "        # Store results for this sub-population\n",
        "        results.append({\n",
        "            \"sub_population\": sub_pop,\n",
        "            \"best_position\": global_best_position,\n",
        "            \"best_value\": objective_function(global_best_position),\n",
        "            \"attention_mechanism\": {'global_weight': global_weight, 'local_weight': local_weight, 'quantum_weight': quantum_weight}\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Set parameters\n",
        "num_states = 10\n",
        "num_particles = 20\n",
        "num_iterations = 30\n",
        "sub_populations = 3  # Number of sub-populations\n",
        "\n",
        "# Initialize quantum state probabilities\n",
        "quantum_probabilities = quantum_exploration(num_states)\n",
        "\n",
        "# Run the Quantum-Swarm Hybrid Algorithm with targeted quantum influence and different learning rates\n",
        "results = swarm_intelligence_targeted(num_particles, num_iterations, quantum_probabilities, sub_populations)\n",
        "\n",
        "# Display the results\n",
        "for result in results:\n",
        "    print(f\"Sub-Population {result['sub_population']} | Best Position: {result['best_position']} | \"\n",
        "          f\"Best Value: {result['best_value']} | Attention Mechanism: {result['attention_mechanism']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhfjOgoH57zL",
        "outputId": "d2160c89-0d46-4131-804a-001563f5e42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub-Population 0 | Best Position: -0.8085523761503022 | Best Value: 0.3338547944254018 | Attention Mechanism: {'global_weight': 0.4989535560743828, 'local_weight': 0.4769788961801397, 'quantum_weight': 0.17495998999885465}\n",
            "Sub-Population 1 | Best Position: -0.8274239910519098 | Best Value: 0.3402151535194474 | Attention Mechanism: {'global_weight': 0.2959856381814876, 'local_weight': 0.35249849967410796, 'quantum_weight': 0.3061548284538497}\n",
            "Sub-Population 2 | Best Position: 0.09467332506734201 | Best Value: 0.451799281580578 | Attention Mechanism: {'global_weight': 0.25467599131685104, 'local_weight': 0.4, 'quantum_weight': 0.15045805180094118}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Objective function to optimize\n",
        "def objective_function(x):\n",
        "    \"\"\"Example objective function to optimize.\"\"\"\n",
        "    return np.sin(5 * x) * (1 - np.tanh(x**2))\n",
        "\n",
        "# Quantum Exploration Phase - Simulate a Quantum State\n",
        "def quantum_exploration(num_states):\n",
        "    \"\"\"Simulate quantum state exploration.\"\"\"\n",
        "    state_amplitudes = np.random.rand(num_states)\n",
        "    state_probabilities = state_amplitudes / np.sum(state_amplitudes)\n",
        "    return state_probabilities\n",
        "\n",
        "# Swarm Intelligence with Dynamic Mutation Rate and Hybrid Search Mechanisms\n",
        "def swarm_intelligence_hybrid(num_particles, num_iterations, quantum_probabilities, sub_populations):\n",
        "    \"\"\"\n",
        "    Perform swarm optimization with multiple sub-populations, using dynamic mutation rates and hybrid search mechanisms.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for sub_pop in range(sub_populations):\n",
        "        particles = np.random.uniform(-5, 5, num_particles)\n",
        "        velocities = np.zeros(num_particles)\n",
        "        best_positions = np.copy(particles)\n",
        "        global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "        # Initialize adaptive attention mechanism with more diversity\n",
        "        global_weight = np.random.uniform(0.2, 0.6)\n",
        "        local_weight = np.random.uniform(0.2, 0.6)\n",
        "        quantum_weight = np.random.uniform(0.1, 0.4)\n",
        "        learning_rate_global = 0.03  # Learning rate for global weight updates\n",
        "        learning_rate_local = 0.03   # Learning rate for local weight updates\n",
        "        learning_rate_quantum = 0.05  # Learning rate for quantum weight updates\n",
        "        decay_factor = 0.98  # Gradual reduction of quantum influence over time\n",
        "        min_quantum_weight = 0.1  # Minimum threshold for quantum influence\n",
        "        mutation_rate = 0.05  # Initial mutation rate\n",
        "\n",
        "        # Phase control parameters\n",
        "        exploration_phase = True\n",
        "        phase_switch_threshold = 5  # Number of iterations without improvement to switch phase\n",
        "        no_improvement_counter = 0\n",
        "\n",
        "        for iteration in range(num_iterations):\n",
        "            for i in range(num_particles):\n",
        "                quantum_feedback = np.random.choice(range(len(quantum_probabilities)), p=quantum_probabilities)\n",
        "                direction = (quantum_feedback - num_particles // 2) / (num_particles // 2)\n",
        "\n",
        "                # Update velocity and position using the hybrid search mechanism\n",
        "                velocities[i] = (local_weight * velocities[i] +\n",
        "                                 local_weight * np.random.rand() * (best_positions[i] - particles[i]) +\n",
        "                                 global_weight * np.random.rand() * (global_best_position - particles[i]) +\n",
        "                                 quantum_weight * direction)\n",
        "                particles[i] += velocities[i]\n",
        "\n",
        "                # Update local best position\n",
        "                if objective_function(particles[i]) > objective_function(best_positions[i]):\n",
        "                    best_positions[i] = particles[i]\n",
        "\n",
        "            # Update global best position\n",
        "            current_best_value = objective_function(global_best_position)\n",
        "            global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "            # Check for performance-based phase transition\n",
        "            if objective_function(global_best_position) <= current_best_value:\n",
        "                no_improvement_counter += 1\n",
        "            else:\n",
        "                no_improvement_counter = 0  # Reset counter on improvement\n",
        "\n",
        "            if exploration_phase and no_improvement_counter >= phase_switch_threshold:\n",
        "                # Switch to exploitation phase\n",
        "                exploration_phase = False\n",
        "                quantum_weight = max(min_quantum_weight, quantum_weight * decay_factor)\n",
        "                global_weight = min(0.6, global_weight + learning_rate_global)\n",
        "                local_weight = min(0.4, local_weight + learning_rate_local)\n",
        "\n",
        "            elif not exploration_phase and no_improvement_counter >= phase_switch_threshold:\n",
        "                # Switch back to exploration phase after prolonged lack of improvement\n",
        "                exploration_phase = True\n",
        "                quantum_weight = min(0.4, quantum_weight + learning_rate_quantum)\n",
        "                global_weight = max(0.3, global_weight - learning_rate_global)\n",
        "                local_weight = max(0.4, local_weight + learning_rate_local)\n",
        "\n",
        "            # Adjust mutation rate dynamically\n",
        "            if no_improvement_counter > phase_switch_threshold:\n",
        "                mutation_rate = min(0.2, mutation_rate * 1.1)  # Increase mutation rate\n",
        "            else:\n",
        "                mutation_rate = max(0.01, mutation_rate * 0.9)  # Decrease mutation rate\n",
        "\n",
        "            # Apply mutation-based exploration\n",
        "            if np.random.rand() < mutation_rate:\n",
        "                # Randomly perturb the best position to introduce diversity\n",
        "                global_best_position += np.random.uniform(-0.1, 0.1)\n",
        "\n",
        "            # Hybrid exploration: occasionally apply random restarts\n",
        "            if iteration % (num_iterations // 3) == 0 and iteration > 0:\n",
        "                particles = np.random.uniform(-5, 5, num_particles)  # Random restart\n",
        "\n",
        "            # Feedback Loop\n",
        "            quantum_probabilities = quantum_exploration(len(quantum_probabilities))\n",
        "\n",
        "        # Store results for this sub-population\n",
        "        results.append({\n",
        "            \"sub_population\": sub_pop,\n",
        "            \"best_position\": global_best_position,\n",
        "            \"best_value\": objective_function(global_best_position),\n",
        "            \"attention_mechanism\": {'global_weight': global_weight, 'local_weight': local_weight, 'quantum_weight': quantum_weight}\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Set parameters\n",
        "num_states = 10\n",
        "num_particles = 20\n",
        "num_iterations = 30\n",
        "sub_populations = 3  # Number of sub-populations\n",
        "\n",
        "# Initialize quantum state probabilities\n",
        "quantum_probabilities = quantum_exploration(num_states)\n",
        "\n",
        "# Run the Quantum-Swarm Hybrid Algorithm with dynamic mutation rates and hybrid search mechanisms\n",
        "results = swarm_intelligence_hybrid(num_particles, num_iterations, quantum_probabilities, sub_populations)\n",
        "\n",
        "# Display the results\n",
        "for result in results:\n",
        "    print(f\"Sub-Population {result['sub_population']} | Best Position: {result['best_position']} | \"\n",
        "          f\"Best Value: {result['best_value']} | Attention Mechanism: {result['attention_mechanism']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spsqGCdc6WMy",
        "outputId": "fb530ee3-05e2-4fbd-aeda-85b8a4d5e12f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub-Population 0 | Best Position: -0.7641348739669606 | Best Value: 0.2980260096871521 | Attention Mechanism: {'global_weight': 0.3330901132726337, 'local_weight': 0.36507320340015403, 'quantum_weight': 0.3355444005507844}\n",
            "Sub-Population 1 | Best Position: 0.3210749440935742 | Best Value: 0.8967381565859434 | Attention Mechanism: {'global_weight': 0.43767320626873685, 'local_weight': 0.5535269753630349, 'quantum_weight': 0.13044986373800976}\n",
            "Sub-Population 2 | Best Position: 0.14778132068118982 | Best Value: 0.6587740617763664 | Attention Mechanism: {'global_weight': 0.4116973541506063, 'local_weight': 0.20433015560043036, 'quantum_weight': 0.11255892838259773}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Objective function to optimize\n",
        "def objective_function(x):\n",
        "    \"\"\"Example objective function to optimize.\"\"\"\n",
        "    return np.sin(5 * x) * (1 - np.tanh(x**2))\n",
        "\n",
        "# Quantum Exploration Phase - Simulate a Quantum State\n",
        "def quantum_exploration(num_states):\n",
        "    \"\"\"Simulate quantum state exploration.\"\"\"\n",
        "    state_amplitudes = np.random.rand(num_states)\n",
        "    state_probabilities = state_amplitudes / np.sum(state_amplitudes)\n",
        "    return state_probabilities\n",
        "\n",
        "# Swarm Intelligence with Adaptive Mutation Rates and Collaborative Information Sharing\n",
        "def swarm_intelligence_collaborative(num_particles, num_iterations, quantum_probabilities, sub_populations):\n",
        "    \"\"\"\n",
        "    Perform swarm optimization with multiple sub-populations, using adaptive mutation rates and collaborative information sharing.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    sub_population_bests = []  # Store the best positions of all sub-populations for collaboration\n",
        "\n",
        "    for sub_pop in range(sub_populations):\n",
        "        particles = np.random.uniform(-5, 5, num_particles)\n",
        "        velocities = np.zeros(num_particles)\n",
        "        best_positions = np.copy(particles)\n",
        "        global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "        # Initialize adaptive attention mechanism with more diversity\n",
        "        global_weight = np.random.uniform(0.2, 0.6)\n",
        "        local_weight = np.random.uniform(0.2, 0.6)\n",
        "        quantum_weight = np.random.uniform(0.1, 0.4)\n",
        "        learning_rate_global = 0.03  # Learning rate for global weight updates\n",
        "        learning_rate_local = 0.03   # Learning rate for local weight updates\n",
        "        learning_rate_quantum = 0.05  # Learning rate for quantum weight updates\n",
        "        decay_factor = 0.98  # Gradual reduction of quantum influence over time\n",
        "        min_quantum_weight = 0.1  # Minimum threshold for quantum influence\n",
        "        mutation_rate = 0.05  # Initial mutation rate\n",
        "\n",
        "        # Phase control parameters\n",
        "        exploration_phase = True\n",
        "        phase_switch_threshold = 5  # Number of iterations without improvement to switch phase\n",
        "        no_improvement_counter = 0\n",
        "\n",
        "        for iteration in range(num_iterations):\n",
        "            for i in range(num_particles):\n",
        "                quantum_feedback = np.random.choice(range(len(quantum_probabilities)), p=quantum_probabilities)\n",
        "                direction = (quantum_feedback - num_particles // 2) / (num_particles // 2)\n",
        "\n",
        "                # Update velocity and position using the hybrid search mechanism\n",
        "                velocities[i] = (local_weight * velocities[i] +\n",
        "                                 local_weight * np.random.rand() * (best_positions[i] - particles[i]) +\n",
        "                                 global_weight * np.random.rand() * (global_best_position - particles[i]) +\n",
        "                                 quantum_weight * direction)\n",
        "                particles[i] += velocities[i]\n",
        "\n",
        "                # Update local best position\n",
        "                if objective_function(particles[i]) > objective_function(best_positions[i]):\n",
        "                    best_positions[i] = particles[i]\n",
        "\n",
        "            # Update global best position\n",
        "            current_best_value = objective_function(global_best_position)\n",
        "            global_best_position = particles[np.argmax([objective_function(x) for x in particles])]\n",
        "\n",
        "            # Check for performance-based phase transition\n",
        "            if objective_function(global_best_position) <= current_best_value:\n",
        "                no_improvement_counter += 1\n",
        "            else:\n",
        "                no_improvement_counter = 0  # Reset counter on improvement\n",
        "\n",
        "            if exploration_phase and no_improvement_counter >= phase_switch_threshold:\n",
        "                # Switch to exploitation phase\n",
        "                exploration_phase = False\n",
        "                quantum_weight = max(min_quantum_weight, quantum_weight * decay_factor)\n",
        "                global_weight = min(0.6, global_weight + learning_rate_global)\n",
        "                local_weight = min(0.4, local_weight + learning_rate_local)\n",
        "\n",
        "            elif not exploration_phase and no_improvement_counter >= phase_switch_threshold:\n",
        "                # Switch back to exploration phase after prolonged lack of improvement\n",
        "                exploration_phase = True\n",
        "                quantum_weight = min(0.4, quantum_weight + learning_rate_quantum)\n",
        "                global_weight = max(0.3, global_weight - learning_rate_global)\n",
        "                local_weight = max(0.4, local_weight + learning_rate_local)\n",
        "\n",
        "            # Adjust mutation rate dynamically based on progress\n",
        "            if no_improvement_counter > phase_switch_threshold:\n",
        "                mutation_rate = min(0.2, mutation_rate * 1.1)  # Increase mutation rate\n",
        "            else:\n",
        "                mutation_rate = max(0.01, mutation_rate * 0.9)  # Decrease mutation rate\n",
        "\n",
        "            # Apply mutation-based exploration\n",
        "            if np.random.rand() < mutation_rate:\n",
        "                # Randomly perturb the best position to introduce diversity\n",
        "                global_best_position += np.random.uniform(-0.1, 0.1)\n",
        "\n",
        "            # Hybrid exploration: occasionally apply random restarts\n",
        "            if iteration % (num_iterations // 3) == 0 and iteration > 0:\n",
        "                particles = np.random.uniform(-5, 5, num_particles)  # Random restart\n",
        "\n",
        "            # Collaborative information sharing\n",
        "            if iteration % 10 == 0 and len(sub_population_bests) > 0:\n",
        "                # Occasionally share best positions among sub-populations\n",
        "                best_shared_position = max(sub_population_bests, key=lambda x: objective_function(x))\n",
        "                global_best_position = best_shared_position\n",
        "\n",
        "            # Feedback Loop\n",
        "            quantum_probabilities = quantum_exploration(len(quantum_probabilities))\n",
        "\n",
        "        # Store results for this sub-population\n",
        "        sub_population_bests.append(global_best_position)  # Share best position for future iterations\n",
        "        results.append({\n",
        "            \"sub_population\": sub_pop,\n",
        "            \"best_position\": global_best_position,\n",
        "            \"best_value\": objective_function(global_best_position),\n",
        "            \"attention_mechanism\": {'global_weight': global_weight, 'local_weight': local_weight, 'quantum_weight': quantum_weight}\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Set parameters\n",
        "num_states = 10\n",
        "num_particles = 20\n",
        "num_iterations = 30\n",
        "sub_populations = 3  # Number of sub-populations\n",
        "\n",
        "# Initialize quantum state probabilities\n",
        "quantum_probabilities = quantum_exploration(num_states)\n",
        "\n",
        "# Run the Quantum-Swarm Hybrid Algorithm with adaptive mutation rates and collaborative sharing\n",
        "results = swarm_intelligence_collaborative(num_particles, num_iterations, quantum_probabilities, sub_populations)\n",
        "\n",
        "# Display the results\n",
        "for result in results:\n",
        "    print(f\"Sub-Population {result['sub_population']} | Best Position: {result['best_position']} | \"\n",
        "          f\"Best Value: {result['best_value']} | Attention Mechanism: {result['attention_mechanism']}\")\n"
      ],
      "metadata": {
        "id": "CcsUmE_S6yuA",
        "outputId": "f087c2cc-caab-4718-d209-d97b187ada4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub-Population 0 | Best Position: 0.12907515584282178 | Best Value: 0.5914784020955988 | Attention Mechanism: {'global_weight': 0.41102171735008153, 'local_weight': 0.4, 'quantum_weight': 0.2813676878816546}\n",
            "Sub-Population 1 | Best Position: -0.8119535989679105 | Best Value: 0.3353749641296731 | Attention Mechanism: {'global_weight': 0.26927521747608757, 'local_weight': 0.24627965051462525, 'quantum_weight': 0.2082473305576773}\n",
            "Sub-Population 2 | Best Position: 0.2332327113370506 | Best Value: 0.869291556968552 | Attention Mechanism: {'global_weight': 0.3749285855172752, 'local_weight': 0.40677340374184745, 'quantum_weight': 0.17253161385533922}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Objective function to optimize\n",
        "def objective_function(x):\n",
        "    \"\"\"Example objective function to optimize, keeping it simple for a noobit simulation.\"\"\"\n",
        "    return np.sin(5 * x) * (1 - np.tanh(x**2))\n",
        "\n",
        "# Initialize the 'Noobit' state representation\n",
        "def initialize_noobit_state(num_noobits):\n",
        "    \"\"\"\n",
        "    Initialize the state of each 'noobit' as a probabilistic representation.\n",
        "    Each noobit will have a simplified superposition state with discrete probabilities.\n",
        "    \"\"\"\n",
        "    # Noobit state is represented by a probability to be in '0' or '1' state\n",
        "    # Each noobit starts with an equal probability to be in either state\n",
        "    noobit_states = np.random.uniform(0.4, 0.6, num_noobits)  # Probabilities centered around 0.5 for 0 and 1\n",
        "    return noobit_states\n",
        "\n",
        "# Simulate Noobit Behavior in PSO\n",
        "def noobit_pso(num_noobits, num_iterations, learning_rate=0.05):\n",
        "    \"\"\"\n",
        "    Perform PSO-like optimization with noobits, each representing a small fraction of a qubit's state.\n",
        "    \"\"\"\n",
        "    # Initialize noobits with random probabilistic states\n",
        "    noobit_states = initialize_noobit_state(num_noobits)\n",
        "    best_positions = np.copy(noobit_states)\n",
        "    global_best_position = np.random.uniform(-1, 1)\n",
        "\n",
        "    # Iterative optimization using 'noobits'\n",
        "    for iteration in range(num_iterations):\n",
        "        for i in range(num_noobits):\n",
        "            # Determine 'noobit' probabilistic state change\n",
        "            random_factor = np.random.uniform(0, 1)\n",
        "            superposition_effect = np.random.normal(loc=0, scale=learning_rate)  # Simulate small quantum-like fluctuation\n",
        "            noobit_states[i] += superposition_effect\n",
        "\n",
        "            # Adjust probabilities to be within [0, 1]\n",
        "            noobit_states[i] = min(max(noobit_states[i], 0), 1)\n",
        "\n",
        "            # Calculate the fitness of the current 'noobit' state\n",
        "            fitness = objective_function(noobit_states[i] * 2 - 1)  # Map [0, 1] to [-1, 1] for the objective function\n",
        "\n",
        "            # Update best positions\n",
        "            if fitness > objective_function(best_positions[i] * 2 - 1):\n",
        "                best_positions[i] = noobit_states[i]\n",
        "\n",
        "            # Update global best position\n",
        "            if fitness > objective_function(global_best_position):\n",
        "                global_best_position = noobit_states[i] * 2 - 1\n",
        "\n",
        "        # Print intermediate results\n",
        "        print(f\"Iteration {iteration + 1}: Global Best Position = {global_best_position}, Fitness = {objective_function(global_best_position)}\")\n",
        "\n",
        "    return global_best_position, objective_function(global_best_position)\n",
        "\n",
        "# Parameters for Noobit Simulation\n",
        "num_noobits = 100  # Total number of noobits (simulating 1/10,000th of a qubit behavior)\n",
        "num_iterations = 30  # Total number of iterations for optimization\n",
        "\n",
        "# Run the Noobit PSO Simulation\n",
        "best_position, best_value = noobit_pso(num_noobits, num_iterations)\n",
        "\n",
        "print(f\"Final Best Position: {best_position}, Objective Function Value: {best_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD8zijyWNnAU",
        "outputId": "59411030-1e93-428d-c2bf-d06f6fd67496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Global Best Position = 0.2880390670321491, Fitness = 0.9094120859352881\n",
            "Iteration 2: Global Best Position = 0.2880390670321491, Fitness = 0.9094120859352881\n",
            "Iteration 3: Global Best Position = 0.2880390670321491, Fitness = 0.9094120859352881\n",
            "Iteration 4: Global Best Position = 0.2880390670321491, Fitness = 0.9094120859352881\n",
            "Iteration 5: Global Best Position = 0.2880390670321491, Fitness = 0.9094120859352881\n",
            "Iteration 6: Global Best Position = 0.2880390670321491, Fitness = 0.9094120859352881\n",
            "Iteration 7: Global Best Position = 0.2886242211319303, Fitness = 0.9094252887125872\n",
            "Iteration 8: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 9: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 10: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 11: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 12: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 13: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 14: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 15: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 16: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 17: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 18: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 19: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 20: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 21: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 22: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 23: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 24: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 25: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 26: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 27: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 28: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 29: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Iteration 30: Global Best Position = 0.2890171732674798, Fitness = 0.9094292769636357\n",
            "Final Best Position: 0.2890171732674798, Objective Function Value: 0.9094292769636357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Objective function to optimize\n",
        "def objective_function(x):\n",
        "    \"\"\"Example objective function to optimize, keeping it simple for a noobit simulation.\"\"\"\n",
        "    return np.sin(5 * x) * (1 - np.tanh(x**2))\n",
        "\n",
        "# Initialize the 'Noobit' state representation\n",
        "def initialize_noobit_state(num_noobits):\n",
        "    \"\"\"\n",
        "    Initialize the state of each 'noobit' as a probabilistic representation.\n",
        "    Each noobit will have a simplified superposition state with discrete probabilities.\n",
        "    \"\"\"\n",
        "    # Noobit state is represented by a probability to be in '0' or '1' state\n",
        "    # Each noobit starts with an equal probability to be in either state\n",
        "    noobit_states = np.random.uniform(0.4, 0.6, num_noobits)  # Probabilities centered around 0.5 for 0 and 1\n",
        "    return noobit_states\n",
        "\n",
        "# Simulate Noobit Behavior in PSO with Enhanced Exploration\n",
        "def noobit_pso_enhanced(num_noobits, num_iterations, learning_rate=0.05, tunneling_prob=0.05):\n",
        "    \"\"\"\n",
        "    Perform PSO-like optimization with noobits, each representing a small fraction of a qubit's state.\n",
        "    Enhanced with adaptive exploration and tunneling.\n",
        "    \"\"\"\n",
        "    # Initialize noobits with random probabilistic states\n",
        "    noobit_states = initialize_noobit_state(num_noobits)\n",
        "    best_positions = np.copy(noobit_states)\n",
        "    global_best_position = np.random.uniform(-1, 1)\n",
        "\n",
        "    # Iterative optimization using 'noobits'\n",
        "    for iteration in range(num_iterations):\n",
        "        for i in range(num_noobits):\n",
        "            # Determine 'noobit' probabilistic state change\n",
        "            random_factor = np.random.uniform(0, 1)\n",
        "            superposition_effect = np.random.normal(loc=0, scale=learning_rate)  # Simulate small quantum-like fluctuation\n",
        "\n",
        "            # Apply tunneling with a certain probability\n",
        "            if np.random.uniform(0, 1) < tunneling_prob:\n",
        "                noobit_states[i] = np.random.uniform(0, 1)  # Random jump to a new state\n",
        "\n",
        "            else:\n",
        "                noobit_states[i] += superposition_effect  # Normal update\n",
        "\n",
        "            # Adjust probabilities to be within [0, 1]\n",
        "            noobit_states[i] = min(max(noobit_states[i], 0), 1)\n",
        "\n",
        "            # Calculate the fitness of the current 'noobit' state\n",
        "            fitness = objective_function(noobit_states[i] * 2 - 1)  # Map [0, 1] to [-1, 1] for the objective function\n",
        "\n",
        "            # Update best positions\n",
        "            if fitness > objective_function(best_positions[i] * 2 - 1):\n",
        "                best_positions[i] = noobit_states[i]\n",
        "\n",
        "            # Update global best position\n",
        "            if fitness > objective_function(global_best_position):\n",
        "                global_best_position = noobit_states[i] * 2 - 1\n",
        "\n",
        "        # Print intermediate results\n",
        "        print(f\"Iteration {iteration + 1}: Global Best Position = {global_best_position}, Fitness = {objective_function(global_best_position)}\")\n",
        "\n",
        "    return global_best_position, objective_function(global_best_position)\n",
        "\n",
        "# Parameters for Enhanced Noobit Simulation\n",
        "num_noobits = 100  # Total number of noobits (simulating 1/10,000th of a qubit behavior)\n",
        "num_iterations = 30  # Total number of iterations for optimization\n",
        "\n",
        "# Run the Enhanced Noobit PSO Simulation\n",
        "best_position, best_value = noobit_pso_enhanced(num_noobits, num_iterations)\n",
        "\n",
        "print(f\"Final Best Position: {best_position}, Objective Function Value: {best_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Md7tl0bOAXd",
        "outputId": "41feefab-7864-4d5c-a46b-9e1c79efa2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Global Best Position = 0.2787886746598285, Fitness = 0.9080451092496125\n",
            "Iteration 2: Global Best Position = 0.2787886746598285, Fitness = 0.9080451092496125\n",
            "Iteration 3: Global Best Position = 0.28673799785883425, Fitness = 0.9093515610540213\n",
            "Iteration 4: Global Best Position = 0.28673799785883425, Fitness = 0.9093515610540213\n",
            "Iteration 5: Global Best Position = 0.28673799785883425, Fitness = 0.9093515610540213\n",
            "Iteration 6: Global Best Position = 0.28899727495585337, Fitness = 0.9094291691859056\n",
            "Iteration 7: Global Best Position = 0.28899727495585337, Fitness = 0.9094291691859056\n",
            "Iteration 8: Global Best Position = 0.28899727495585337, Fitness = 0.9094291691859056\n",
            "Iteration 9: Global Best Position = 0.28899727495585337, Fitness = 0.9094291691859056\n",
            "Iteration 10: Global Best Position = 0.28899727495585337, Fitness = 0.9094291691859056\n",
            "Iteration 11: Global Best Position = 0.28899727495585337, Fitness = 0.9094291691859056\n",
            "Iteration 12: Global Best Position = 0.28899727495585337, Fitness = 0.9094291691859056\n",
            "Iteration 13: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 14: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 15: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 16: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 17: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 18: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 19: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 20: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 21: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 22: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 23: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 24: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 25: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 26: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 27: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 28: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 29: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Iteration 30: Global Best Position = 0.28942179665114365, Fitness = 0.9094292898531023\n",
            "Final Best Position: 0.28942179665114365, Objective Function Value: 0.9094292898531023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Objective function to optimize\n",
        "def objective_function(x):\n",
        "    \"\"\"Example objective function to optimize, keeping it simple for a noobit simulation.\"\"\"\n",
        "    return np.sin(5 * x) * (1 - np.tanh(x**2))\n",
        "\n",
        "# Initialize the 'Noobit' state representation\n",
        "def initialize_noobit_state(num_noobits):\n",
        "    \"\"\"\n",
        "    Initialize the state of each 'noobit' as a probabilistic representation.\n",
        "    Each noobit will have a simplified superposition state with discrete probabilities.\n",
        "    \"\"\"\n",
        "    # Noobit state is represented by a probability to be in '0' or '1' state\n",
        "    noobit_states = np.random.uniform(0.4, 0.6, num_noobits)  # Probabilities centered around 0.5 for 0 and 1\n",
        "    return noobit_states\n",
        "\n",
        "# Simulate Noobit Behavior in PSO with Dynamic Tunneling and Entanglement\n",
        "def noobit_pso_advanced(num_noobits, num_iterations, initial_tunneling_prob=0.05, learning_rate=0.05):\n",
        "    \"\"\"\n",
        "    Perform PSO-like optimization with noobits, each representing a small fraction of a qubit's state.\n",
        "    Enhanced with dynamic tunneling and entanglement-like interactions.\n",
        "    \"\"\"\n",
        "    # Initialize noobits with random probabilistic states\n",
        "    noobit_states = initialize_noobit_state(num_noobits)\n",
        "    best_positions = np.copy(noobit_states)\n",
        "    global_best_position = np.random.uniform(-1, 1)\n",
        "\n",
        "    tunneling_prob = initial_tunneling_prob  # Dynamic tunneling probability\n",
        "\n",
        "    # Iterative optimization using 'noobits'\n",
        "    for iteration in range(num_iterations):\n",
        "        for i in range(num_noobits):\n",
        "            # Determine 'noobit' probabilistic state change\n",
        "            superposition_effect = np.random.normal(loc=0, scale=learning_rate)  # Simulate small quantum-like fluctuation\n",
        "\n",
        "            # Apply dynamic tunneling with a certain probability\n",
        "            if np.random.uniform(0, 1) < tunneling_prob:\n",
        "                noobit_states[i] = np.random.uniform(0, 1)  # Random jump to a new state\n",
        "\n",
        "            else:\n",
        "                noobit_states[i] += superposition_effect  # Normal update\n",
        "\n",
        "            # Adjust probabilities to be within [0, 1]\n",
        "            noobit_states[i] = min(max(noobit_states[i], 0), 1)\n",
        "\n",
        "            # Entanglement-like behavior: influence neighboring noobits\n",
        "            if i > 0:  # Update based on previous noobit\n",
        "                noobit_states[i] = (noobit_states[i] + noobit_states[i - 1]) / 2\n",
        "\n",
        "            # Calculate the fitness of the current 'noobit' state\n",
        "            fitness = objective_function(noobit_states[i] * 2 - 1)  # Map [0, 1] to [-1, 1] for the objective function\n",
        "\n",
        "            # Update best positions\n",
        "            if fitness > objective_function(best_positions[i] * 2 - 1):\n",
        "                best_positions[i] = noobit_states[i]\n",
        "\n",
        "            # Update global best position\n",
        "            if fitness > objective_function(global_best_position):\n",
        "                global_best_position = noobit_states[i] * 2 - 1\n",
        "\n",
        "        # Adjust tunneling probability dynamically based on stagnation\n",
        "        if iteration > 5 and global_best_position == noobit_states[np.argmax([objective_function(x * 2 - 1) for x in noobit_states])]:\n",
        "            tunneling_prob = min(0.1, tunneling_prob + 0.01)  # Increase tunneling probability\n",
        "        else:\n",
        "            tunneling_prob = max(0.01, tunneling_prob - 0.01)  # Decrease tunneling probability\n",
        "\n",
        "        # Print intermediate results\n",
        "        print(f\"Iteration {iteration + 1}: Global Best Position = {global_best_position}, Fitness = {objective_function(global_best_position)}\")\n",
        "\n",
        "    return global_best_position, objective_function(global_best_position)\n",
        "\n",
        "# Parameters for Advanced Noobit Simulation\n",
        "num_noobits = 100  # Total number of noobits (simulating 1/10,000th of a qubit behavior)\n",
        "num_iterations = 30  # Total number of iterations for optimization\n",
        "\n",
        "# Run the Advanced Noobit PSO Simulation\n",
        "best_position, best_value = noobit_pso_advanced(num_noobits, num_iterations)\n",
        "\n",
        "print(f\"Final Best Position: {best_position}, Objective Function Value: {best_value}\")\n"
      ],
      "metadata": {
        "id": "MlXWWLUpOW7B",
        "outputId": "d72c024b-91e4-420c-a7ec-fa045668d4f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Global Best Position = 0.27696037668265516, Fitness = 0.9075162741455722\n",
            "Iteration 2: Global Best Position = 0.27696037668265516, Fitness = 0.9075162741455722\n",
            "Iteration 3: Global Best Position = 0.2949933747752709, Fitness = 0.9090080361707953\n",
            "Iteration 4: Global Best Position = 0.2949933747752709, Fitness = 0.9090080361707953\n",
            "Iteration 5: Global Best Position = 0.2949933747752709, Fitness = 0.9090080361707953\n",
            "Iteration 6: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 7: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 8: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 9: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 10: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 11: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 12: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 13: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 14: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 15: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 16: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 17: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 18: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 19: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 20: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 21: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 22: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 23: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 24: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 25: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 26: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 27: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 28: Global Best Position = 0.2913750045591126, Fitness = 0.9093709866424828\n",
            "Iteration 29: Global Best Position = 0.29072776730788163, Fitness = 0.9094010127476747\n",
            "Iteration 30: Global Best Position = 0.29072776730788163, Fitness = 0.9094010127476747\n",
            "Final Best Position: 0.29072776730788163, Objective Function Value: 0.9094010127476747\n"
          ]
        }
      ]
    }
  ]
}